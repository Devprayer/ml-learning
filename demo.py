#!/usr/bin/env python3
"""
DBGNNè‚¡ç¥¨é¢„æµ‹æ¨¡å‹æ¼”ç¤ºè„šæœ¬

è¿™ä¸ªè„šæœ¬æ¼”ç¤ºäº†å¦‚ä½•ï¼š
1. ç”Ÿæˆæ¨¡æ‹Ÿè‚¡ç¥¨æ•°æ®
2. è®­ç»ƒDBGNNæ¨¡å‹
3. è¿›è¡Œé¢„æµ‹å’Œä¸ç¡®å®šæ€§ä¼°è®¡
4. å¯è§†åŒ–ç»“æœ
"""

import torch
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime, timedelta
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import warnings
warnings.filterwarnings('ignore')

from dbgnn_model import DBGNN, DBGNNLoss
from stock_data_generator import StockDataGenerator
from train_dbgnn import DBGNNTrainer


def quick_demo():
    """å¿«é€Ÿæ¼”ç¤ºï¼šç”Ÿæˆæ•°æ®å¹¶å±•ç¤ºåŸºæœ¬åŠŸèƒ½"""
    
    print("ğŸš€ DBGNNè‚¡ç¥¨é¢„æµ‹æ¨¡å‹æ¼”ç¤º")
    print("=" * 50)
    
    # 1. æ•°æ®ç”Ÿæˆ
    print("\nğŸ“Š ç¬¬ä¸€æ­¥ï¼šç”Ÿæˆæ¨¡æ‹Ÿè‚¡ç¥¨æ•°æ®")
    generator = StockDataGenerator(num_stocks=20, time_periods=200, seed=42)
    
    # ç”Ÿæˆä»·æ ¼æ•°æ®
    price_data = generator.generate_stock_prices(
        initial_price=100.0,
        volatility=0.02,
        drift=0.0005
    )
    
    # è®¡ç®—æŠ€æœ¯æŒ‡æ ‡
    features_data = generator.calculate_technical_indicators(price_data)
    
    # å±•ç¤ºæ•°æ®ç»Ÿè®¡
    generator.get_data_statistics(price_data, features_data)
    
    # å¯è§†åŒ–æ ·æœ¬è‚¡ç¥¨
    print("\nğŸ“ˆ è‚¡ç¥¨ä»·æ ¼èµ°åŠ¿å›¾")
    generator.plot_sample_stocks(price_data, num_samples=5)
    
    # å¯è§†åŒ–è‚¡ç¥¨å…³ç³»ç½‘ç»œ
    print("\nğŸ•¸ï¸ è‚¡ç¥¨ç›¸å…³æ€§ç½‘ç»œå›¾")
    generator.visualize_stock_network(correlation_threshold=0.25)
    
    return generator, price_data, features_data


def train_demo_model(generator, price_data, features_data):
    """è®­ç»ƒæ¼”ç¤ºæ¨¡å‹"""
    
    print("\nğŸ¤– ç¬¬äºŒæ­¥ï¼šè®­ç»ƒDBGNNæ¨¡å‹")
    
    # å‡†å¤‡å›¾æ•°æ®
    graph_data_list = generator.prepare_time_series_data(
        price_data, features_data, sequence_length=10, prediction_horizon=1
    )
    
    print(f"ç”Ÿæˆäº† {len(graph_data_list)} ä¸ªå›¾æ•°æ®æ ·æœ¬")
    print(f"èŠ‚ç‚¹ç‰¹å¾ç»´åº¦: {graph_data_list[0].x.shape[1]}")
    print(f"è¾¹æ•°é‡: {graph_data_list[0].edge_index.shape[1]}")
    
    # åˆå§‹åŒ–æ¨¡å‹
    input_dim = graph_data_list[0].x.shape[1]
    model = DBGNN(
        input_dim=input_dim,
        hidden_dim=32,  # å‡å°‘éšè—å±‚ç»´åº¦åŠ å¿«è®­ç»ƒ
        output_dim=1,
        num_layers=2,   # å‡å°‘å±‚æ•°
        dropout=0.1,
        prior_std=1.0
    )
    
    print(f"æ¨¡å‹å‚æ•°æ•°é‡: {sum(p.numel() for p in model.parameters()):,}")
    
    # åˆå§‹åŒ–è®­ç»ƒå™¨
    trainer = DBGNNTrainer(model, log_dir='demo_logs', model_save_dir='demo_models')
    
    # å‡†å¤‡æ•°æ®åŠ è½½å™¨
    train_loader, val_loader, test_loader = trainer.prepare_data_loaders(
        graph_data_list, batch_size=8
    )
    
    # å¿«é€Ÿè®­ç»ƒï¼ˆå‡å°‘epochæ•°ç”¨äºæ¼”ç¤ºï¼‰
    print("\nğŸƒâ€â™‚ï¸ å¼€å§‹å¿«é€Ÿè®­ç»ƒï¼ˆæ¼”ç¤ºæ¨¡å¼ï¼‰...")
    history = trainer.train(
        train_loader=train_loader,
        val_loader=val_loader,
        epochs=50,      # å‡å°‘epochæ•°
        learning_rate=0.01,
        kl_weight=1e-3,
        patience=10
    )
    
    return trainer, test_loader, history


def analyze_predictions(trainer, test_loader):
    """åˆ†æé¢„æµ‹ç»“æœ"""
    
    print("\nğŸ“Š ç¬¬ä¸‰æ­¥ï¼šåˆ†æé¢„æµ‹ç»“æœ")
    
    # è¯„ä¼°æ¨¡å‹
    metrics, predictions, targets, uncertainties = trainer.evaluate(test_loader)
    
    # åˆ›å»ºè¯¦ç»†çš„å¯è§†åŒ–
    fig = plt.figure(figsize=(20, 15))
    
    # 1. é¢„æµ‹vsçœŸå®å€¼æ•£ç‚¹å›¾
    plt.subplot(3, 3, 1)
    plt.scatter(targets, predictions, alpha=0.6, c=uncertainties, cmap='viridis')
    plt.plot([targets.min(), targets.max()], [targets.min(), targets.max()], 'r--', lw=2)
    plt.xlabel('True Return Rate')
    plt.ylabel('Predicted Return Rate')
    plt.title(f'Predictions vs True Values\n(RÂ²={metrics["r2"]:.3f})')
    plt.colorbar(label='Uncertainty')
    plt.grid(True, alpha=0.3)
    
    # 2. æ®‹å·®åˆ†æ
    plt.subplot(3, 3, 2)
    residuals = predictions.flatten() - targets.flatten()
    plt.scatter(predictions.flatten(), residuals, alpha=0.6)
    plt.axhline(y=0, color='r', linestyle='--', linewidth=2)
    plt.xlabel('Predictions')
    plt.ylabel('Residuals')
    plt.title('Residual Analysis')
    plt.grid(True, alpha=0.3)
    
    # 3. ä¸ç¡®å®šæ€§åˆ†å¸ƒ
    plt.subplot(3, 3, 3)
    plt.hist(uncertainties.flatten(), bins=30, alpha=0.7, color='skyblue', edgecolor='black')
    plt.xlabel('Uncertainty')
    plt.ylabel('Frequency')
    plt.title('Prediction Uncertainty Distribution')
    plt.grid(True, alpha=0.3)
    
    # 4. é¢„æµ‹å‡†ç¡®æ€§åˆ†ç®±åˆ†æ
    plt.subplot(3, 3, 4)
    uncertainty_bins = np.percentile(uncertainties, [0, 25, 50, 75, 100])
    bin_labels = ['Low', 'Medium-Low', 'Medium-High', 'High']
    bin_accuracies = []
    
    for i in range(len(uncertainty_bins)-1):
        mask = (uncertainties >= uncertainty_bins[i]) & (uncertainties < uncertainty_bins[i+1])
        if i == len(uncertainty_bins)-2:  # æœ€åä¸€ä¸ªbinåŒ…å«æœ€å¤§å€¼
            mask = (uncertainties >= uncertainty_bins[i]) & (uncertainties <= uncertainty_bins[i+1])
        
        if np.sum(mask) > 0:
            bin_predictions = predictions[mask]
            bin_targets = targets[mask]
            bin_mse = np.mean((bin_predictions - bin_targets)**2)
            bin_accuracies.append(bin_mse)
        else:
            bin_accuracies.append(0)
    
    plt.bar(bin_labels, bin_accuracies, alpha=0.7, color='coral')
    plt.xlabel('Uncertainty Level')
    plt.ylabel('Mean Squared Error')
    plt.title('Prediction Error by Uncertainty Level')
    plt.xticks(rotation=45)
    plt.grid(True, alpha=0.3)
    
    # 5. æ–¹å‘å‡†ç¡®æ€§åˆ†æ
    plt.subplot(3, 3, 5)
    pred_direction = np.sign(predictions.flatten())
    true_direction = np.sign(targets.flatten())
    
    # åˆ›å»ºæ··æ·†çŸ©é˜µ
    from sklearn.metrics import confusion_matrix
    cm = confusion_matrix(true_direction, pred_direction, labels=[-1, 1])
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                xticklabels=['Down', 'Up'], yticklabels=['Down', 'Up'])
    plt.xlabel('Predicted Direction')
    plt.ylabel('True Direction')
    plt.title(f'Direction Accuracy: {metrics["direction_accuracy"]:.3f}')
    
    # 6. æ—¶é—´åºåˆ—é¢„æµ‹ç¤ºä¾‹
    plt.subplot(3, 3, 6)
    # é€‰æ‹©å‰50ä¸ªæ ·æœ¬è¿›è¡Œå¯è§†åŒ–
    sample_size = min(50, len(predictions))
    time_steps = range(sample_size)
    plt.plot(time_steps, targets[:sample_size], 'b-', label='True', linewidth=2)
    plt.plot(time_steps, predictions[:sample_size], 'r--', label='Predicted', linewidth=2)
    plt.fill_between(time_steps, 
                     predictions[:sample_size].flatten() - uncertainties[:sample_size].flatten(),
                     predictions[:sample_size].flatten() + uncertainties[:sample_size].flatten(),
                     alpha=0.3, color='red', label='Uncertainty')
    plt.xlabel('Time Steps')
    plt.ylabel('Return Rate')
    plt.title('Time Series Prediction Sample')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    # 7. ç‰¹å¾é‡è¦æ€§åˆ†æï¼ˆåŸºäºæ¢¯åº¦ï¼‰
    plt.subplot(3, 3, 7)
    # ç®€åŒ–çš„ç‰¹å¾é‡è¦æ€§å¯è§†åŒ–
    feature_names = ['Sector', 'Price_Mean', 'Price_Std', 'Return', 'MA_Short', 'MA_Long', 'RSI', 'Volatility', 'Price_Position']
    # æ¨¡æ‹Ÿç‰¹å¾é‡è¦æ€§ï¼ˆå®é™…åº”ç”¨ä¸­éœ€è¦è®¡ç®—çœŸå®çš„ç‰¹å¾é‡è¦æ€§ï¼‰
    importance_scores = np.random.rand(len(feature_names))
    importance_scores = importance_scores / importance_scores.sum()
    
    plt.barh(feature_names, importance_scores, alpha=0.7, color='lightgreen')
    plt.xlabel('Relative Importance')
    plt.title('Feature Importance (Simulated)')
    plt.grid(True, alpha=0.3)
    
    # 8. æŸå¤±å‡½æ•°ç»„ä»¶åˆ†æ
    plt.subplot(3, 3, 8)
    history = trainer.train_history
    epochs = history['epoch']
    plt.plot(epochs, history['train_mse'], label='Train MSE', color='blue')
    plt.plot(epochs, history['val_mse'], label='Val MSE', color='red')
    plt.plot(epochs, np.array(history['train_kl'])*1000, label='Train KLÃ—1000', color='green')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.title('Training Loss Components')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    # 9. ä¸ç¡®å®šæ€§æ ¡å‡†å›¾
    plt.subplot(3, 3, 9)
    # å°†ä¸ç¡®å®šæ€§åˆ†ä¸º10ä¸ªåŒºé—´
    n_bins = 10
    uncertainty_percentiles = np.linspace(0, 100, n_bins+1)
    bin_boundaries = np.percentile(uncertainties, uncertainty_percentiles)
    
    bin_centers = []
    bin_errors = []
    
    for i in range(n_bins):
        if i == n_bins-1:
            mask = (uncertainties >= bin_boundaries[i]) & (uncertainties <= bin_boundaries[i+1])
        else:
            mask = (uncertainties >= bin_boundaries[i]) & (uncertainties < bin_boundaries[i+1])
        
        if np.sum(mask) > 0:
            bin_uncertainty = uncertainties[mask].mean()
            bin_error = np.abs(predictions[mask] - targets[mask]).mean()
            bin_centers.append(bin_uncertainty)
            bin_errors.append(bin_error)
    
    plt.scatter(bin_centers, bin_errors, alpha=0.7, s=50, color='purple')
    if bin_centers and bin_errors:
        plt.plot([min(bin_centers), max(bin_centers)], 
                [min(bin_centers), max(bin_centers)], 'r--', label='Perfect Calibration')
    plt.xlabel('Predicted Uncertainty')
    plt.ylabel('Actual Error')
    plt.title('Uncertainty Calibration')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig('demo_results_analysis.png', dpi=300, bbox_inches='tight')
    plt.show()
    
    return metrics, predictions, targets, uncertainties


def create_interactive_visualization(generator, price_data, predictions, targets, uncertainties):
    """åˆ›å»ºäº¤äº’å¼å¯è§†åŒ–"""
    
    print("\nğŸ¨ ç¬¬å››æ­¥ï¼šåˆ›å»ºäº¤äº’å¼å¯è§†åŒ–")
    
    # åˆ›å»ºPlotlyäº¤äº’å¼å›¾è¡¨
    fig = make_subplots(
        rows=2, cols=2,
        subplot_titles=('Stock Price Evolution', 'Prediction vs Reality', 
                       'Uncertainty Analysis', 'Performance Metrics'),
        specs=[[{"secondary_y": False}, {"secondary_y": False}],
               [{"secondary_y": False}, {"type": "table"}]]
    )
    
    # 1. è‚¡ç¥¨ä»·æ ¼æ¼”å˜
    sample_stocks = generator.stock_symbols[:5]
    for stock in sample_stocks:
        fig.add_trace(
            go.Scatter(x=price_data.index, y=price_data[stock], 
                      mode='lines', name=stock, opacity=0.7),
            row=1, col=1
        )
    
    # 2. é¢„æµ‹vsçœŸå®å€¼
    fig.add_trace(
        go.Scatter(x=targets.flatten(), y=predictions.flatten(),
                  mode='markers', name='Predictions',
                  marker=dict(color=uncertainties.flatten(), 
                            colorscale='Viridis', showscale=True,
                            colorbar=dict(title="Uncertainty")),
                  text=[f'Uncertainty: {u:.4f}' for u in uncertainties.flatten()]),
        row=1, col=2
    )
    
    # æ·»åŠ ç†æƒ³çº¿
    min_val, max_val = targets.min(), targets.max()
    fig.add_trace(
        go.Scatter(x=[min_val, max_val], y=[min_val, max_val],
                  mode='lines', name='Perfect Prediction', 
                  line=dict(dash='dash', color='red')),
        row=1, col=2
    )
    
    # 3. ä¸ç¡®å®šæ€§åˆ†æ
    fig.add_trace(
        go.Histogram(x=uncertainties.flatten(), name='Uncertainty Distribution',
                    opacity=0.7, nbinsx=30),
        row=2, col=1
    )
    
    # 4. æ€§èƒ½æŒ‡æ ‡è¡¨æ ¼
    from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
    
    mse = mean_squared_error(targets, predictions)
    mae = mean_absolute_error(targets, predictions)
    r2 = r2_score(targets, predictions)
    
    # è®¡ç®—æ–¹å‘å‡†ç¡®ç‡
    pred_direction = np.sign(predictions.flatten())
    true_direction = np.sign(targets.flatten())
    direction_accuracy = np.mean(pred_direction == true_direction)
    
    metrics_table = go.Table(
        header=dict(values=['Metric', 'Value'],
                   fill_color='lightblue'),
        cells=dict(values=[['MSE', 'MAE', 'RÂ²', 'Direction Accuracy', 'Mean Uncertainty'],
                          [f'{mse:.6f}', f'{mae:.6f}', f'{r2:.4f}', 
                           f'{direction_accuracy:.4f}', f'{np.mean(uncertainties):.6f}']],
                  fill_color='white')
    )
    
    fig.add_trace(metrics_table, row=2, col=2)
    
    # æ›´æ–°å¸ƒå±€
    fig.update_layout(
        title_text="DBGNN Stock Prediction Model - Interactive Dashboard",
        title_x=0.5,
        height=800,
        showlegend=True
    )
    
    fig.update_xaxes(title_text="Date", row=1, col=1)
    fig.update_yaxes(title_text="Price", row=1, col=1)
    fig.update_xaxes(title_text="True Values", row=1, col=2)
    fig.update_yaxes(title_text="Predictions", row=1, col=2)
    fig.update_xaxes(title_text="Uncertainty", row=2, col=1)
    fig.update_yaxes(title_text="Frequency", row=2, col=1)
    
    # ä¿å­˜ä¸ºHTMLæ–‡ä»¶
    fig.write_html("dbgnn_interactive_dashboard.html")
    print("ğŸ“± äº¤äº’å¼Dashboardå·²ä¿å­˜ä¸º 'dbgnn_interactive_dashboard.html'")
    
    # æ˜¾ç¤ºå›¾è¡¨
    fig.show()


def generate_prediction_report(metrics, predictions, targets, uncertainties):
    """ç”Ÿæˆé¢„æµ‹æŠ¥å‘Š"""
    
    print("\nğŸ“‹ ç¬¬äº”æ­¥ï¼šç”Ÿæˆé¢„æµ‹æŠ¥å‘Š")
    
    report = f"""
    ========================================
           DBGNN è‚¡ç¥¨é¢„æµ‹æ¨¡å‹æŠ¥å‘Š
    ========================================
    
    æ¨¡å‹æ€§èƒ½æŒ‡æ ‡:
    ----------------------------------------
    â€¢ å‡æ–¹è¯¯å·® (MSE):          {metrics['mse']:.6f}
    â€¢ å¹³å‡ç»å¯¹è¯¯å·® (MAE):      {metrics['mae']:.6f}
    â€¢ å†³å®šç³»æ•° (RÂ²):           {metrics['r2']:.4f}
    â€¢ æ–¹å‘å‡†ç¡®ç‡:              {metrics['direction_accuracy']:.4f}
    â€¢ å¹³å‡ä¸ç¡®å®šæ€§:            {metrics['mean_uncertainty']:.6f}
    
    æ•°æ®ç»Ÿè®¡:
    ----------------------------------------
    â€¢ æµ‹è¯•æ ·æœ¬æ•°é‡:            {len(predictions)}
    â€¢ é¢„æµ‹å€¼èŒƒå›´:              [{predictions.min():.4f}, {predictions.max():.4f}]
    â€¢ çœŸå®å€¼èŒƒå›´:              [{targets.min():.4f}, {targets.max():.4f}]
    â€¢ ä¸ç¡®å®šæ€§èŒƒå›´:            [{uncertainties.min():.4f}, {uncertainties.max():.4f}]
    
    æ¨¡å‹ç‰¹ç‚¹:
    ----------------------------------------
    â€¢ âœ… è´å¶æ–¯ç¥ç»ç½‘ç»œæä¾›ä¸ç¡®å®šæ€§ä¼°è®¡
    â€¢ âœ… å›¾ç¥ç»ç½‘ç»œæ•æ‰è‚¡ç¥¨é—´å…³ç³»
    â€¢ âœ… æŠ€æœ¯æŒ‡æ ‡å’Œä»·æ ¼ç‰¹å¾èåˆ
    â€¢ âœ… å˜åˆ†æ¨ç†å®ç°å‚æ•°ä¸ç¡®å®šæ€§
    â€¢ âœ… KLæ•£åº¦æ­£åˆ™åŒ–é˜²æ­¢è¿‡æ‹Ÿåˆ
    
    ä½¿ç”¨å»ºè®®:
    ----------------------------------------
    1. é«˜ä¸ç¡®å®šæ€§é¢„æµ‹éœ€è¦è°¨æ…å¯¹å¾…
    2. ç»“åˆä¼ ç»Ÿåˆ†ææ–¹æ³•ä½¿ç”¨
    3. å®šæœŸé‡è®­ç»ƒæ¨¡å‹ä»¥é€‚åº”å¸‚åœºå˜åŒ–
    4. ç›‘æ§æ¨¡å‹æ€§èƒ½æŒ‡æ ‡çš„å˜åŒ–
    
    ========================================
    """
    
    print(report)
    
    # ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶
    with open('dbgnn_prediction_report.txt', 'w', encoding='utf-8') as f:
        f.write(report)
    
    print("ğŸ“„ æŠ¥å‘Šå·²ä¿å­˜ä¸º 'dbgnn_prediction_report.txt'")


def main():
    """ä¸»æ¼”ç¤ºå‡½æ•°"""
    
    print("ğŸ¯ å¼€å§‹DBGNNå®Œæ•´æ¼”ç¤ºæµç¨‹\n")
    
    try:
        # 1. å¿«é€Ÿæ¼”ç¤ºï¼šæ•°æ®ç”Ÿæˆå’Œå¯è§†åŒ–
        generator, price_data, features_data = quick_demo()
        
        # 2. æ¨¡å‹è®­ç»ƒ
        trainer, test_loader, history = train_demo_model(generator, price_data, features_data)
        
        # 3. ç»“æœåˆ†æ
        metrics, predictions, targets, uncertainties = analyze_predictions(trainer, test_loader)
        
        # 4. äº¤äº’å¼å¯è§†åŒ–
        create_interactive_visualization(generator, price_data, predictions, targets, uncertainties)
        
        # 5. ç”ŸæˆæŠ¥å‘Š
        generate_prediction_report(metrics, predictions, targets, uncertainties)
        
        print("\nğŸ‰ æ¼”ç¤ºå®Œæˆï¼")
        print("\nğŸ“ ç”Ÿæˆçš„æ–‡ä»¶:")
        print("   â€¢ demo_results_analysis.png - ç»“æœåˆ†æå›¾")
        print("   â€¢ dbgnn_interactive_dashboard.html - äº¤äº’å¼Dashboard")
        print("   â€¢ dbgnn_prediction_report.txt - é¢„æµ‹æŠ¥å‘Š")
        print("   â€¢ demo_logs/ - è®­ç»ƒæ—¥å¿—")
        print("   â€¢ demo_models/ - è®­ç»ƒå¥½çš„æ¨¡å‹")
        
    except Exception as e:
        print(f"âŒ æ¼”ç¤ºè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()